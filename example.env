# Python Virtual Environment
TILDROOT=/user/example/LLM-UQ-with-TM
ENV_DIR=/user/example/LLM-UQ-with-TM/.env
PIP_DIR=/user/example/lmenv/bin/activate
MODEL_DIR=/user/example/LLM-UQ-with-TM/models
CSV_PATH=/user/example/LLM-UQ-with-TM/dataset/uq
GLOVE_DIR=/user/example/LLM-UQ-with-TM/glove/
# RUNNING PARAMETERS
SEED=999
RUST_BACKTRACE=full
# SLURM Settings 
ACCOUNT=hpc-account
RUN_TYPE=ok
PARTITION=GPUQ
TIMEOUT=14-00:00:00
NB_NODES=1
NB_TASKS_PER_NODE=2
CPUS_PER_TASK=4
GRES=gpu:1
MEM=120GB
CONSTRAINT="gpu80g"
OUTPUT_DIR=/user/example/LLM-UQ-with-TM/logs
# LABEL-CRITIC TM Settings
TM_RUN_TYPE=test
TM_PARTITION=GPUQ
TM_JOB_NAME=lctm-train
TM_TIMEOUT=7-00:00:00
TM_NB_NODES=1
TM_NB_TASKS_PER_NODE=2
TM_CPUS_PER_TASK=2
TM_GRES=gpu:p100:1
TM_MEM=32GB
# LLAMA SETUP
LLAMA_31_URL="https://llama3-1.llamameta.net/*?Policy=TOKEN"
LLAMA_32_URL="https://llama3-2-lightweight.llamameta.net/*?Policy=TOKEN"
LLAMA_31_MD5_CHECKSUMS=/user/example/.llama/checkpoints/Llama3.1-8B/checklist.chk
LLAMA_32_1B_MD5_CHECKSUMS=/user/example/.llama/checkpoints/Llama3.2-1B/checklist.chk
CKPT_DIR=$TILDROOT/.llama/checkpoints/
# HGFACE SETUP
HGF_TOKEN="TOKEN_HERE"