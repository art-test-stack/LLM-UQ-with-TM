# Python Virtual Environment
ENV_DIR=~/LLM-UQ-with-TM/.env
PIP_DIR=~/lmenv/bin/activate
MODEL_DIR=~/LLM-UQ-with-TM/models
CSV_PATH=~/LLM-UQ-with-TM/dataset/uq
GLOVE_DIR=~/LLM-UQ-with-TM/glove/
# RUNNING PARAMETERS
PARAMS_FILE_TORCH=~/LLM-UQ-with-TM/configs/torch.yaml
PARAMS_FILE_LLAMA=~/LLM-UQ-with-TM/configs/llama3.2.yaml
SEED=999
RUST_BACKTRACE=full
# SLURM Settings 
ACCOUNT=account
RUN_TYPE=test
PARTITION=GPUQ
JOB_NAME_TORCH=one-gpu.easy.glv 
JOB_NAME_LLAMA=make-tm-dataset.llama
TIMEOUT=0-30:10:00
NB_NODES=1
NB_TASKS_PER_NODE=2
CPUS_PER_TASK=4
GRES=gpu:1
MEM=80GB
CONSTRAINT="gpu80g"
OUTPUT_DIR=logs
# LABEL-CRITIC TM Settings
TM_RUN_TYPE=test
TM_PARTITION=GPUQ
TM_JOB_NAME=lc-tm-run
TM_TIMEOUT=0-24:00:00
TM_NB_NODES=2
TM_NB_TASKS_PER_NODE=2
TM_CPUS_PER_TASK=2
TM_GRES=gpu:2
TM_MEM=32GB
# LLAMA SETUP
LLAMA_31_URL="https://llama3-1.llamameta.net/key"
LLAMA_32_URL="https://llama3-2-lightweight.llamameta.net/key"
CKPT_DIR=llama/ckpt/dir